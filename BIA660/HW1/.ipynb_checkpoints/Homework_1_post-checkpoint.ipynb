{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center>Homework 1</center></h1>\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Please read the problem description carefully\n",
    "- Make sure to complete all requirement (shown as bullets) . In general, it would be much easier if you complete the requirements in the order as shown in the problem description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all my personal notes begin with #***\n",
    "### all code blocks with orignal results not been run for comparation\n",
    "### for q2, the code blocks with orignal results hasnt been upadted, pls compare with the one in the new HW1-notebook if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze the frequency of words in a string (3 points)\n",
    " - Define a function which does the following:\n",
    "     * has a string as an input\n",
    "     * splits the string into a list of tokens by space. \n",
    "         - e.g., \"it's a hello world!!!\" will be split into two tokens [\"it's\", \"a\",\"hello\",\"world!!!\"]   \n",
    "     * if a token starts with or ends with one or more punctuations, remove these punctuations, e.g. \"world<font color=\"red\">!!!</font>\" -> \"world\".(<font color=\"blue\">hint, you can import module *string*, use *string.punctuation* to get a list of punctuations, and then use function *strip()* to remove leading or trailing punctuations </font>) \n",
    "     * remove the space surrounding each token\n",
    "     * only keep tokens with 3 or more characters\n",
    "     * convert all tokens into lower case \n",
    "     * create a dictionary to save the count of each unique word \n",
    "     * sort the dictionary by word count in descending order\n",
    "     * return the sorted dictionary \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def text_analyzer_q1(text):\n",
    "    \n",
    "    # initialize a list\n",
    "    pun = string.punctuation\n",
    "    \n",
    "    # add your code here\n",
    "    text = text.lower()\n",
    "    \n",
    "    # split by space (including \\tab and \\n)\n",
    "    text = text.split() \n",
    "    \n",
    "    # clean up tokens\n",
    "    #*** cu_text for cleaned up text\n",
    "    text = list(map(lambda word :word.strip(pun), text))\n",
    "    cu_text = [word for word in text if len(word) >= 3]\n",
    "    \n",
    "    # initialize a dict\n",
    "    #*** cw_dict for count word dict\n",
    "    cw_dict = {}\n",
    "    \n",
    "    # count token frequency\n",
    "    for word in cu_text:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if word in cw_dict.keys():\n",
    "                cw_dict[word] = cw_dict[word] + 1\n",
    "            else:\n",
    "                cw_dict[word] = 1\n",
    "    \n",
    "    # sort the dict by value\n",
    "    cw_dict = dict(sorted(cw_dict.items(), key = lambda x: x[1], reverse = True))\n",
    "\n",
    "    return cw_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 5,\n",
       " 'and': 3,\n",
       " 'covid-19': 2,\n",
       " 'vaccines': 2,\n",
       " 'preventing': 2,\n",
       " 'severe': 2,\n",
       " 'recent': 2,\n",
       " 'their': 2,\n",
       " 'fully': 2,\n",
       " 'vaccinated': 2,\n",
       " 'two': 2,\n",
       " 'weeks': 2,\n",
       " 'after': 2,\n",
       " 'such': 2,\n",
       " 'vaccine': 2,\n",
       " 'optimally': 2,\n",
       " 'protected': 2,\n",
       " 'although': 1,\n",
       " 'remain': 1,\n",
       " 'effective': 1,\n",
       " 'disease': 1,\n",
       " 'data': 1,\n",
       " 'suggest': 1,\n",
       " 'effectiveness': 1,\n",
       " 'infection': 1,\n",
       " 'illness': 1,\n",
       " 'wanes': 1,\n",
       " 'over': 1,\n",
       " 'time': 1,\n",
       " 'especially': 1,\n",
       " 'people': 1,\n",
       " 'ages': 1,\n",
       " 'years': 1,\n",
       " 'older.the': 1,\n",
       " 'emergence': 1,\n",
       " 'omicron': 1,\n",
       " 'variant': 1,\n",
       " 'further': 1,\n",
       " 'emphasizes': 1,\n",
       " 'importance': 1,\n",
       " 'vaccination': 1,\n",
       " 'boosters': 1,\n",
       " 'prevention': 1,\n",
       " 'efforts': 1,\n",
       " 'needed': 1,\n",
       " 'protect': 1,\n",
       " 'against': 1,\n",
       " 'everyone': 1,\n",
       " 'still': 1,\n",
       " 'considered': 1,\n",
       " 'second': 1,\n",
       " 'dose': 1,\n",
       " 'two-shot': 1,\n",
       " 'series': 1,\n",
       " 'pfizer-biontech': 1,\n",
       " 'moderna': 1,\n",
       " 'single-dose': 1,\n",
       " 'j&j/janssen': 1,\n",
       " 'however': 1,\n",
       " 'not': 1,\n",
       " 'same': 1,\n",
       " 'person': 1,\n",
       " 'needs': 1,\n",
       " 'get': 1,\n",
       " 'booster': 1,\n",
       " 'shot': 1,\n",
       " 'when': 1,\n",
       " 'eligible': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code\n",
    "text = '''Although COVID-19 vaccines remain effective in preventing severe disease, recent data suggest their \\\n",
    "effectiveness at preventing infection or severe illness wanes over time, especially in people ages 65 years and older.\\\n",
    "The recent emergence of the Omicron variant further emphasizes the importance of vaccination, boosters, and \\\n",
    "prevention efforts needed to protect against COVID-19. Everyone is still considered fully vaccinated two weeks after their second dose \\\n",
    "in a two-shot series, such as the Pfizer-BioNTech or Moderna vaccines, or two weeks after a single-dose vaccine, \\\n",
    "such as the J&J/Janssen vaccine. Fully vaccinated, however is not the same as optimally protected.  \\\n",
    "To be optimally protected, a person needs to get a booster shot when and if eligible.\n",
    "'''\n",
    "\n",
    "text_analyzer_q1(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 5,\n",
       " 'and': 3,\n",
       " 'covid-19': 2,\n",
       " 'vaccines': 2,\n",
       " 'preventing': 2,\n",
       " 'severe': 2,\n",
       " 'recent': 2,\n",
       " 'their': 2,\n",
       " 'fully': 2,\n",
       " 'vaccinated': 2,\n",
       " 'two': 2,\n",
       " 'weeks': 2,\n",
       " 'after': 2,\n",
       " 'such': 2,\n",
       " 'vaccine': 2,\n",
       " 'optimally': 2,\n",
       " 'protected': 2,\n",
       " 'although': 1,\n",
       " 'remain': 1,\n",
       " 'effective': 1,\n",
       " 'disease': 1,\n",
       " 'data': 1,\n",
       " 'suggest': 1,\n",
       " 'effectiveness': 1,\n",
       " 'infection': 1,\n",
       " 'illness': 1,\n",
       " 'wanes': 1,\n",
       " 'over': 1,\n",
       " 'time': 1,\n",
       " 'especially': 1,\n",
       " 'people': 1,\n",
       " 'ages': 1,\n",
       " 'years': 1,\n",
       " 'older.the': 1,\n",
       " 'emergence': 1,\n",
       " 'omicron': 1,\n",
       " 'variant': 1,\n",
       " 'further': 1,\n",
       " 'emphasizes': 1,\n",
       " 'importance': 1,\n",
       " 'vaccination': 1,\n",
       " 'boosters': 1,\n",
       " 'prevention': 1,\n",
       " 'efforts': 1,\n",
       " 'needed': 1,\n",
       " 'protect': 1,\n",
       " 'against': 1,\n",
       " 'everyone': 1,\n",
       " 'still': 1,\n",
       " 'considered': 1,\n",
       " 'second': 1,\n",
       " 'dose': 1,\n",
       " 'two-shot': 1,\n",
       " 'series': 1,\n",
       " 'pfizer-biontech': 1,\n",
       " 'moderna': 1,\n",
       " 'single-dose': 1,\n",
       " 'j&j/janssen': 1,\n",
       " 'however': 1,\n",
       " 'not': 1,\n",
       " 'same': 1,\n",
       " 'person': 1,\n",
       " 'needs': 1,\n",
       " 'get': 1,\n",
       " 'booster': 1,\n",
       " 'shot': 1,\n",
       " 'when': 1,\n",
       " 'eligible': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code\n",
    "text = '''Although COVID-19 vaccines remain effective in preventing severe disease, recent data suggest their \\\n",
    "effectiveness at preventing infection or severe illness wanes over time, especially in people ages 65 years and older.\\\n",
    "The recent emergence of the Omicron variant further emphasizes the importance of vaccination, boosters, and \\\n",
    "prevention efforts needed to protect against COVID-19. Everyone is still considered fully vaccinated two weeks after their second dose \\\n",
    "in a two-shot series, such as the Pfizer-BioNTech or Moderna vaccines, or two weeks after a single-dose vaccine, \\\n",
    "such as the J&J/Janssen vaccine. Fully vaccinated, however is not the same as optimally protected.  \\\n",
    "To be optimally protected, a person needs to get a booster shot when and if eligible.\n",
    "'''\n",
    "\n",
    "\n",
    "text_analyzer_q1(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze a numpy array (4 points)\n",
    " - Assume we have an array $X$ which contains term frequency of each document. In this array, each row presents a document, each column denotes a word, and each value, say $x_{i,j}$,  denotes the frequency of the word $j$ in document $i$. Therefore, if there are  $m$ documents, $n$ words, $X$ has a shape of $(m, n)$.\n",
    " \n",
    " Define a function which:\n",
    "      * Take array $X$ as an input.\n",
    "      * Divides word frequency $x_{i,j}$ by the total number of words in document $i$. Save the result as an array named $tf$ ($tf$ has shape of $(m,n)$).\n",
    "      * Calculate the document frequency $df_j$ for word $j$, e.g. how many documents contain word $j$. Save the result to array $df$ ($df$ shape becomes $(n,)$, it's better to keep the dimensions). Note: for this step you need to first convert the array to binary.\n",
    "      * Calculate $idf_j =  ln(\\frac{|m|}{df_j})+1$. m is the number of documents. The reason is, if a word appears in most documents, it does not have the discriminative power. The inverse of $df$ can downgrade the weight of such words. \n",
    "      * Finally, for each $x_{i,j}$, calculates $tf\\_idf_{i,j} = tf_(i,j) * idf_j$. ($tf\\_idf$ has shape of $(m,n)$).\n",
    "      * Now, please print the following:\n",
    "          * print the index of the longest document\n",
    "          * print the indexes of words with the top 4 largest $df$ values\n",
    "          * for the longest document, print the indexes of words with top 3 largest values in the $tf\\_idf$ array (use the index you got previously). \n",
    "      * Return the $tf\\_idf$ array.\n",
    " - Note, for all the steps, **do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analyzer_q2(Xarray):\n",
    "    \n",
    "    # get tf \n",
    "    X = pd.DataFrame(Xarray)\n",
    "    tf = X.div(X.sum(axis=1), axis=0)\n",
    "    \n",
    "    # get df\n",
    "    df = X.astype(bool).astype(int)\n",
    "    df = df.apply(lambda x:x.sum())\n",
    "\n",
    "    # get idf\n",
    "    idf = df.map(lambda x: np.log(len(X)/x)+1)\n",
    "    \n",
    "    # get tf_idf\n",
    "    tf_idf = tf * idf\n",
    "    \n",
    "    #print index of the longest documents\n",
    "    topld = list(X.apply(lambda x: x.sum(), axis=1))\n",
    "    top_x = topld.index(max(topld))\n",
    "    print(\"Indexes of the longest documents: {}\".format(top_x))\n",
    "    \n",
    "    #print indexes of words with the top 4 largest 𝑑𝑓 values\n",
    "    df4l = df.sort_values(ascending=False)\n",
    "    top_df = list(df4l.index[0:4])\n",
    "    print(\"Indexes of words with the top 4 largest df values: {}\".format(top_df))\n",
    "    \n",
    "    #return index of top_3 words with largest tf_idf values for the longest document\n",
    "    toptfidf = tf_idf.iloc[top_x]\n",
    "    tfidf3l = toptfidf.sort_values(ascending=False)\n",
    "    top_tf_idf = list(tfidf3l.index[0:3])\n",
    "    print(\"Indexes of words with top 3 largest tf_idf values in the longest document: {}\".format(top_tf_idf))\n",
    "    \n",
    "    return tf_idf.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of the longest documents: 3\n",
      "Indexes of words with the top 4 largest df values: [12, 86, 85, 43]\n",
      "Indexes of words with top 3 largest tf_idf values in the longest document: [14, 56, 44]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.11345382, 0.        ,\n",
       "        0.13137614, 0.11345382, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13043478, 0.11345382, 0.        ,\n",
       "        0.        , 0.        , 0.08331699, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11345382, 0.06568807, 0.        , 0.11345382,\n",
       "        0.        , 0.        , 0.        , 0.08331699, 0.        ,\n",
       "        0.        , 0.11345382, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.06568807, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11345382,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08331699, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06568807,\n",
       "        0.        , 0.        , 0.06568807, 0.08331699, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10636031, 0.05318015, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04      , 0.        , 0.        ,\n",
       "        0.10437752, 0.10437752, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.10437752, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.10437752, 0.07665163, 0.10437752,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10437752, 0.10437752,\n",
       "        0.        , 0.10437752, 0.10437752, 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.10437752, 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10437752, 0.        , 0.        , 0.07665163,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04892574, 0.10437752, 0.10437752, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.100363  , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.100363  , 0.100363  ,\n",
       "        0.        , 0.        , 0.03846154, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20072599, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.100363  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.100363  , 0.        , 0.        ,\n",
       "        0.20072599, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.100363  , 0.        , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20072599, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.20072599,\n",
       "        0.100363  , 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04704398, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.0467388 ,\n",
       "        0.11054822, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.12728965, 0.02439024, 0.        , 0.25457931,\n",
       "        0.        , 0.        , 0.0467388 , 0.        , 0.        ,\n",
       "        0.06364483, 0.        , 0.06364483, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.03684941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0467388 , 0.06364483,\n",
       "        0.        , 0.        , 0.        , 0.03684941, 0.12728965,\n",
       "        0.        , 0.        , 0.06364483, 0.        , 0.        ,\n",
       "        0.06364483, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06364483, 0.12728965, 0.0467388 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.12728965,\n",
       "        0.        , 0.        , 0.06364483, 0.        , 0.03684941,\n",
       "        0.        , 0.        , 0.11054822, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0934776 ,\n",
       "        0.        , 0.12728965, 0.        , 0.        , 0.06364483,\n",
       "        0.02983277, 0.02983277, 0.        , 0.        , 0.06364483,\n",
       "        0.        ],\n",
       "       [0.09664585, 0.        , 0.        , 0.        , 0.07097373,\n",
       "        0.11191301, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09664585, 0.        , 0.07407407, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09664585,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09664585, 0.        , 0.0559565 , 0.09664585, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07097373, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0559565 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09664585,\n",
       "        0.        , 0.09664585, 0.09664585, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07097373, 0.        , 0.        ,\n",
       "        0.07097373, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0559565 ,\n",
       "        0.        , 0.        , 0.0559565 , 0.07097373, 0.        ,\n",
       "        0.        , 0.        , 0.09664585, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09664585, 0.09664585, 0.        ,\n",
       "        0.04530161, 0.04530161, 0.        , 0.        , 0.        ,\n",
       "        0.09664585]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*** below is note before dtm file updated\n",
    "#*** this read_csv fuction may need to add index_col = 0 as it's using first column as index, \n",
    "#*** but to make sure gaining the same result, I didn't add it.\n",
    "#*** ends here\n",
    "\n",
    "#*** for Indexes of words with the top 4 largest df values\n",
    "#*** and the Indexes of words with top 3 largest tf_idf values in the longest document\n",
    "#*** there are several same 2rd largest values, so the result mightbe different\n",
    "dtm = pd.read_csv(\"dtm.csv\")\n",
    "text_analyzer_q2(dtm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of the longest documents: 3\n",
      "Indexes of words with the top 4 largest df values: [13  0 87 86]\n",
      "Indexes of words with top 3 largest tf_idf values in the longest document: [15 45 82]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.11345382,\n",
       "        0.        , 0.13137614, 0.11345382, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13043478, 0.11345382,\n",
       "        0.        , 0.        , 0.        , 0.08331699, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11345382, 0.06568807, 0.        ,\n",
       "        0.11345382, 0.        , 0.        , 0.        , 0.08331699,\n",
       "        0.        , 0.        , 0.11345382, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06568807,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11345382, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08331699, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06568807, 0.        , 0.        , 0.06568807, 0.08331699,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10636031, 0.05318015, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.04704398, 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03846154, 0.        ,\n",
       "        0.        , 0.100363  , 0.100363  , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.100363  , 0.        , 0.100363  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.100363  , 0.100363  , 0.07370349,\n",
       "        0.100363  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.100363  , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.100363  ,\n",
       "        0.100363  , 0.        , 0.100363  , 0.100363  , 0.        ,\n",
       "        0.        , 0.        , 0.100363  , 0.        , 0.100363  ,\n",
       "        0.        , 0.        , 0.100363  , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.100363  , 0.        , 0.        ,\n",
       "        0.07370349, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04704398, 0.100363  , 0.100363  ,\n",
       "        0.        , 0.        ],\n",
       "       [0.0873674 , 0.        , 0.09319421, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09319421,\n",
       "        0.09319421, 0.        , 0.        , 0.03571429, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18638842,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09319421, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09319421, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09319421, 0.        , 0.09319421, 0.        ,\n",
       "        0.        , 0.18638842, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09319421, 0.09319421, 0.        , 0.09319421,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18638842,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09319421,\n",
       "        0.        , 0.09319421, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09319421, 0.        , 0.        , 0.        ,\n",
       "        0.18638842, 0.09319421, 0.        , 0.        , 0.09319421,\n",
       "        0.        , 0.09319421, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0436837 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.08339615, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04355206, 0.10301084, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11861081, 0.02272727, 0.        ,\n",
       "        0.23722163, 0.        , 0.        , 0.04355206, 0.        ,\n",
       "        0.        , 0.05930541, 0.        , 0.05930541, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03433695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04355206,\n",
       "        0.05930541, 0.        , 0.        , 0.        , 0.03433695,\n",
       "        0.11861081, 0.        , 0.        , 0.05930541, 0.        ,\n",
       "        0.        , 0.05930541, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05930541, 0.11861081, 0.04355206, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11861081, 0.        , 0.        , 0.05930541, 0.        ,\n",
       "        0.03433695, 0.        , 0.        , 0.10301084, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08710412, 0.        , 0.11861081, 0.        , 0.        ,\n",
       "        0.05930541, 0.02779872, 0.02779872, 0.        , 0.        ,\n",
       "        0.05930541, 0.        ],\n",
       "       [0.15782497, 0.08417542, 0.        , 0.        , 0.        ,\n",
       "        0.06181583, 0.09747262, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08417542, 0.        , 0.06451613, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08417542, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08417542, 0.        , 0.04873631, 0.08417542,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06181583,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04873631,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08417542, 0.        , 0.08417542, 0.08417542, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.06181583, 0.        ,\n",
       "        0.        , 0.06181583, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04873631, 0.        , 0.        , 0.04873631, 0.06181583,\n",
       "        0.        , 0.        , 0.        , 0.08417542, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08417542, 0.08417542,\n",
       "        0.        , 0.03945624, 0.03945624, 0.        , 0.        ,\n",
       "        0.        , 0.08417542]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*** this hasnt been updated, pls check the new HW file instead\n",
    "# dtm.csv is a csv file for test. \n",
    "# It contains word counts in a few documents\n",
    "dtm = pd.read_csv(\"dtm.csv\")\n",
    "text_analyzer_q2(dtm.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Define a function to analyze a dataset using pandas (3 points)\n",
    "\n",
    "- The dataset \"emotion.csv\" contains a number of text and ten types of sentiment scores. Define a function named `emotion_analysis` to do the follows:\n",
    "   * Read \"emotion.csv\" as a dataframe with the first row in the csv file as column names\n",
    "   * Count the number of samples labeled for each emotion (i.e. each value in the column \"emotion). Print the counts.\n",
    "   * Add a column \"length\" that calculates the number of words for each text. (hint: \"apply\" function to split the text by space and then count elements in the resulting list)\n",
    "   * Show the min, max, and mean values of sadness, happiness, and text length for each emotion. Print the results.\n",
    "   * Create a cross tabulation of average anxiety scores. Use \"emotion\" as row index, \"worry\" as column index, and \"length\" as values. Print the table.\n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_analysis():\n",
    "    \n",
    "    # read data\n",
    "    df=pd.read_csv(\"emotion.csv\", header=0)\n",
    "    print(df)\n",
    "    \n",
    "    # Count the number of samples labeled for each emotion\n",
    "    print(\"===The number of samples labeled for each emotion===\")\n",
    "    print(df['emotion'].value_counts())\n",
    "    \n",
    "    # Create a new column called \"length\"   \n",
    "    df['length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Show the min, max, and mean values\n",
    "    print(\"\\n\")\n",
    "    print(\"=== min, max, and mean values of sadness, happiness, and text length for each emotion===\")\n",
    "    dfshown = df.groupby(['emotion']).agg(['mean','min','max'])\n",
    "    dfshown = dfshown.drop(['anxiety','worry','anger','disgust','fear','relaxation','desire'], axis=1)\n",
    "    print(dfshown)\n",
    "\n",
    "    # get cross tab\n",
    "    print(\"\\n\")\n",
    "    print(\"=== Cross tabulation of length by emotion and worry ===\")\n",
    "    dfcr = pd.pivot_table(df,index=[u'emotion'],columns=[u'worry'],values=[u'length'],aggfunc=[np.mean])\n",
    "    print(dfcr)\n",
    "\n",
    "    # add your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      worry     emotion  anger  disgust  fear  anxiety  sadness  happiness  \\\n",
      "0         3     Sadness      5        5     3        7        7          2   \n",
      "1         8     Anxiety      6        7     7        8        6          4   \n",
      "2         4  Relaxation      1        1     2        2        4          7   \n",
      "3         6  Relaxation      4        2     3        4        1          6   \n",
      "4         6     Anxiety      2        2     5        5        5          4   \n",
      "...     ...         ...    ...      ...   ...      ...      ...        ...   \n",
      "2486      3      Desire      2        1     2        3        4          7   \n",
      "2487      8        Fear      2        5     8        8        8          1   \n",
      "2488      7        Fear      7        5     7        7        7          4   \n",
      "2489      7     Anxiety      4        6     7        7        8          4   \n",
      "2490      8        Fear      7        2     9        9        7          2   \n",
      "\n",
      "      relaxation  desire                                               text  \n",
      "0              4       5  It is less an much an issue of how it affects ...  \n",
      "1              3       1  I am concerned that the true impact of the cur...  \n",
      "2              7       2  Personally, I am fairly calm about the corona ...  \n",
      "3              7       3  In this very moment as I am fortunate to be ab...  \n",
      "4              4       4  I am more worried about getting access to my n...  \n",
      "...          ...     ...                                                ...  \n",
      "2486           6       8  I feel sad for the loss of life and the pain t...  \n",
      "2487           2       3  I fear  that  the virus is more deadly than  w...  \n",
      "2488           2       2  I feel stressed and anxious about people ignor...  \n",
      "2489           5       5  It is quite worrying even though it said to ha...  \n",
      "2490           2       1  I feel helpless that in reality there's nothin...  \n",
      "\n",
      "[2491 rows x 11 columns]\n",
      "===The number of samples labeled for each emotion===\n",
      "Anxiety       1381\n",
      "Sadness        357\n",
      "Relaxation     333\n",
      "Fear           230\n",
      "Anger          107\n",
      "Happiness       39\n",
      "Desire          27\n",
      "Disgust         17\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "\n",
      "=== min, max, and mean values of sadness, happiness, and text length for each emotion===\n",
      "             sadness         happiness              length          \n",
      "                mean min max      mean min max        mean min   max\n",
      "emotion                                                             \n",
      "Anger       5.672897   1   9  3.177570   1   8  118.897196  85   312\n",
      "Anxiety     5.719768   1   9  3.333816   1   9  117.431571  59   540\n",
      "Desire      4.148148   1   8  4.925926   2   8  150.592593  88  1016\n",
      "Disgust     4.764706   1   8  3.764706   1   6  108.529412  60   158\n",
      "Fear        6.565217   1   9  3.056522   1   9  118.039130  80   319\n",
      "Happiness   2.666667   1   9  7.230769   4   9  121.358974  92   274\n",
      "Relaxation  2.858859   1   9  5.369369   1   9  117.804805   6   297\n",
      "Sadness     7.436975   2   9  3.112045   1   9  120.375350  75   547\n",
      "\n",
      "\n",
      "=== Cross tabulation of length by emotion and worry ===\n",
      "               mean                                                  \\\n",
      "             length                                                   \n",
      "worry             1           2           3           4           5   \n",
      "emotion                                                               \n",
      "Anger       171.000  119.000000  106.416667  111.777778  129.750000   \n",
      "Anxiety     124.000  127.166667  114.000000  118.382353  109.827586   \n",
      "Desire          NaN   93.500000  110.571429  129.750000  119.333333   \n",
      "Disgust         NaN   84.000000         NaN  128.500000  102.200000   \n",
      "Fear            NaN         NaN   99.000000  124.666667  105.714286   \n",
      "Happiness   104.000  138.333333  117.200000  108.400000  111.500000   \n",
      "Relaxation  114.875  116.277778  126.113208  113.432836  121.136364   \n",
      "Sadness     107.000  105.571429  127.368421  113.575758  118.529412   \n",
      "\n",
      "                                                            \n",
      "                                                            \n",
      "worry                6           7           8           9  \n",
      "emotion                                                     \n",
      "Anger       118.000000  110.000000  109.153846  143.125000  \n",
      "Anxiety     117.603053  118.248988  116.754717  119.869565  \n",
      "Desire      225.750000  140.666667         NaN         NaN  \n",
      "Disgust     107.200000  114.250000         NaN         NaN  \n",
      "Fear        116.272727  118.393443  116.328767  120.851351  \n",
      "Happiness   127.875000  127.200000  112.000000  122.500000  \n",
      "Relaxation  113.379310  117.975610  117.875000  121.100000  \n",
      "Sadness     116.542169  119.637255  132.782609  123.838710  \n"
     ]
    }
   ],
   "source": [
    "#*** for the cross tab, I go along with mean(length) as the value, it does have a slightly difference as shown though.\n",
    "emotion_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   worry  emotion  anger  disgust  fear  anxiety  sadness  happiness  \\\n",
      "0      3  Sadness      5        5     3        7        7          2   \n",
      "1      8  Anxiety      6        7     7        8        6          4   \n",
      "\n",
      "   relaxation  desire                                               text  \n",
      "0           4       5  It is less an much an issue of how it affects ...  \n",
      "1           3       1  I am concerned that the true impact of the cur...  \n",
      "===The number of samples labeled for each emotion===\n",
      "Anxiety       1381\n",
      "Sadness        357\n",
      "Relaxation     333\n",
      "Fear           230\n",
      "Anger          107\n",
      "Happiness       39\n",
      "Desire          27\n",
      "Disgust         17\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "\n",
      "=== min, max, and mean values of sadness, happiness, and text length for each emotion===\n",
      "             sadness           happiness                length           \n",
      "                mean amin amax      mean amin amax        mean amin  amax\n",
      "emotion                                                                  \n",
      "Anger       5.672897    1    9  3.177570    1    8  122.084112   88   374\n",
      "Anxiety     5.719768    1    9  3.333816    1    9  118.066618   59   541\n",
      "Desire      4.148148    1    8  4.925926    2    8  150.259259   89  1018\n",
      "Disgust     4.764706    1    8  3.764706    1    6  108.411765   58   158\n",
      "Fear        6.565217    1    9  3.056522    1    9  118.852174   80   322\n",
      "Happiness   2.666667    1    9  7.230769    4    9  122.461538   92   272\n",
      "Relaxation  2.858859    1    9  5.369369    1    9  119.696697    1   292\n",
      "Sadness     7.436975    2    9  3.112045    1    9  122.117647   85   544\n",
      "\n",
      "\n",
      "=== Cross tabulation of length by emotion and worry ===\n",
      "worry                1           2           3           4           5  \\\n",
      "emotion                                                                  \n",
      "Anger       173.000000  119.750000  106.916667  112.222222  130.500000   \n",
      "Anxiety     121.000000  127.666667  114.277778  118.264706  110.206897   \n",
      "Desire             NaN   91.500000  110.428571  129.750000  119.333333   \n",
      "Disgust            NaN   83.000000         NaN  128.500000  102.000000   \n",
      "Fear               NaN         NaN   99.000000  125.333333  113.857143   \n",
      "Happiness   106.333333  137.833333  117.800000  110.400000  109.500000   \n",
      "Relaxation  114.875000  116.027778  126.075472  115.671642  123.659091   \n",
      "Sadness     105.500000  105.285714  127.578947  113.636364  119.058824   \n",
      "\n",
      "worry                6           7           8           9  \n",
      "emotion                                                     \n",
      "Anger       134.722222  110.360000  109.076923  143.687500  \n",
      "Anxiety     118.209924  118.937247  117.600629  120.335404  \n",
      "Desire      226.625000  137.000000         NaN         NaN  \n",
      "Disgust     107.000000  114.500000         NaN         NaN  \n",
      "Fear        116.454545  118.639344  117.808219  120.891892  \n",
      "Happiness   130.625000  127.200000  114.333333  123.000000  \n",
      "Relaxation  116.724138  122.146341  118.000000  122.400000  \n",
      "Sadness     117.409639  121.627451  139.413043  124.580645  \n"
     ]
    }
   ],
   "source": [
    "emotion_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus question (1 point)\n",
    "1. Suppose your machine learning model returns a list of probabilities as the output. Write a function to do the following:\n",
    "    - Given a threshold, say $th$, if a probability > $th$, the prediction is positive; otherwise, negative\n",
    "    - Compare the prediction with the ground truth labels to calculate the confusion matrix as [[TN, FN],[FP,TP]], where:\n",
    "        * True Positives (TP): the number of correct positive predictions\n",
    "        * False Positives (FP): the number of postive predictives which actually are negatives\n",
    "        * True Negatives (TN): the number of correct negative predictions\n",
    "        * False Negatives (FN): the number of negative predictives which actually are positives\n",
    "    - Calculate **precision** as $TP/(TP+FP)$ and **recall** as $TP/(TP+FN)$\n",
    "    - return precision and recall. \n",
    "2. Call this function with $th$ varying from 0.05 to 0.95 with an increase of 0.05. Plot a line chart to see how precision and recall change by $th$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob =np.array([0.28997326, 0.10166073, 0.10759583, 0.0694934 , 0.6767239 ,\n",
    "       0.01446897, 0.15268748, 0.15570522, 0.12159665, 0.22593857,\n",
    "       0.98162019, 0.47418329, 0.09376987, 0.80440782, 0.88361167,\n",
    "       0.21579844, 0.72343069, 0.06605903, 0.15447797, 0.10967575,\n",
    "       0.93020135, 0.06570391, 0.05283854, 0.09668829, 0.05974545,\n",
    "       0.04874688, 0.07562255, 0.11103822, 0.71674525, 0.08507381,\n",
    "       0.630128  , 0.16447478, 0.16914903, 0.1715767 , 0.08040751,\n",
    "       0.7001173 , 0.04428363, 0.19469664, 0.12247959, 0.14000294,\n",
    "       0.02411263, 0.26276603, 0.11377073, 0.07055441, 0.2021157 ,\n",
    "       0.11636899, 0.90348488, 0.10191679, 0.88744523, 0.18938904])\n",
    "\n",
    "truth = np.array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
    "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(prob, truth, th):\n",
    "    conf = [[0, 0], [0, 0]]\n",
    "    \n",
    "    # add your code here\n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == 1 and prob[i] > th:\n",
    "           conf[1][1] += 1\n",
    "        if truth[i] == 0 and prob[i] > th:\n",
    "           conf[1][0] += 1\n",
    "        if truth[i] == 0 and prob[i] <= th:\n",
    "           conf[0][0] += 1\n",
    "        if truth[i] == 1 and prob[i] <= th:\n",
    "           conf[0][1] += 1\n",
    "    \n",
    "    metric = {}\n",
    "    metric['R0'] = conf[1][1]/(conf[1][1]+conf[1][0])\n",
    "    metric['R1'] = conf[1][1]/(conf[1][1]+conf[0][1])\n",
    "    \n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R0': 0.2608695652173913, 'R1': 1.0}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_performance(prob, truth, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R0': 0.2608695652173913, 'R1': 1.0}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with one value\n",
    "evaluate_performance(prob, truth, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with threhold grid\n",
    "th = 0.05\n",
    "df = pd.DataFrame()\n",
    "while(th < 1):\n",
    "    a = evaluate_performance(prob, truth, th)\n",
    "    a['th'] = th\n",
    "    th += 0.05\n",
    "    df = df.append(a, ignore_index=True)\n",
    "df_new = df.set_index('th',drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "df_new.columns = ['prec','rec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          prec       rec\n",
      "th                      \n",
      "0.05  0.260870  1.000000\n",
      "0.10  0.342857  1.000000\n",
      "0.15  0.480000  1.000000\n",
      "0.20  0.705882  1.000000\n",
      "0.25  0.857143  1.000000\n",
      "0.30  0.916667  0.916667\n",
      "0.35  0.916667  0.916667\n",
      "0.40  0.916667  0.916667\n",
      "0.45  0.916667  0.916667\n",
      "0.50  0.909091  0.833333\n",
      "0.55  0.909091  0.833333\n",
      "0.60  0.909091  0.833333\n",
      "0.65  0.900000  0.750000\n",
      "0.70  0.888889  0.666667\n",
      "0.75  1.000000  0.500000\n",
      "0.80  1.000000  0.500000\n",
      "0.85  1.000000  0.416667\n",
      "0.90  1.000000  0.250000\n",
      "0.95  1.000000  0.083333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "print(df_new)\n",
    "x = np.arange(0.05,1.00,0.05)\n",
    "y1 = df_new['prec']\n",
    "y2 = df_new['rec']\n",
    "\n",
    "plt.plot(x, y1, label = 'prec') \n",
    "plt.plot(x, y2, label = 'rec') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          prec       rec\n",
      "0.05  0.260870  1.000000\n",
      "0.10  0.342857  1.000000\n",
      "0.15  0.480000  1.000000\n",
      "0.20  0.705882  1.000000\n",
      "0.25  0.857143  1.000000\n",
      "0.30  0.916667  0.916667\n",
      "0.35  0.916667  0.916667\n",
      "0.40  0.916667  0.916667\n",
      "0.45  0.916667  0.916667\n",
      "0.50  0.909091  0.833333\n",
      "0.55  0.909091  0.833333\n",
      "0.60  0.909091  0.833333\n",
      "0.65  0.900000  0.750000\n",
      "0.70  0.888889  0.666667\n",
      "0.75  1.000000  0.500000\n",
      "0.80  1.000000  0.500000\n",
      "0.85  1.000000  0.416667\n",
      "0.90  1.000000  0.250000\n",
      "0.95  1.000000  0.083333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce80767310>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
